{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './MNIST-data/raw'\n",
    "\n",
    "# location of data and labels\n",
    "test_labels_file = data_path + '/' + 't10k-labels-idx1-ubyte'\n",
    "test_data_file = data_path + '/' + 't10k-images-idx3-ubyte'\n",
    "train_labels_file = data_path + '/' + 'train-labels-idx1-ubyte'\n",
    "train_data_file = data_path + '/' + 'train-images-idx3-ubyte'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dset: Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Split: train\n",
      "    Root Location: ./MNIST-data/raw\n",
      "    Transforms (if any): Compose(\n",
      "                             ToTensor()\n",
      "                             Normalize(mean=(0.5,), std=(1.0,))\n",
      "                         )\n",
      "    Target Transforms (if any): None\n",
      "Test dset: Dataset MNIST\n",
      "    Number of datapoints: 10000\n",
      "    Split: test\n",
      "    Root Location: ./MNIST-data/raw\n",
      "    Transforms (if any): Compose(\n",
      "                             ToTensor()\n",
      "                             Normalize(mean=(0.5,), std=(1.0,))\n",
      "                         )\n",
      "    Target Transforms (if any): None\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.datasets as dsets\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,))])\n",
    "#trans = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# pytorch datasets that download MNIST set as needed; used only to download files\n",
    "train_dset = dsets.MNIST(root=data_path, download=False, train=True, transform=trans)\n",
    "test_dset = dsets.MNIST(root=data_path, download=False, train=False, transform=trans)\n",
    "\n",
    "print(\"Training dset:\", train_dset)\n",
    "print(\"Test dset:\", test_dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training target 0: (tensor([[[-0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
      "          -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
      "          -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
      "          -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000],\n",
      "         [-0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
      "          -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
      "          -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
      "          -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000],\n",
      "         [-0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
      "          -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
      "          -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
      "          -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000],\n",
      "         [-0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
      "          -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
      "          -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
      "          -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000],\n",
      "         [-0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
      "          -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
      "          -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
      "          -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000],\n",
      "         [-0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
      "          -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.4882, -0.4294,\n",
      "          -0.4294, -0.4294, -0.0059,  0.0333,  0.1863, -0.3980,  0.1510,\n",
      "           0.5000,  0.4686, -0.0020, -0.5000, -0.5000, -0.5000, -0.5000],\n",
      "         [-0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
      "          -0.5000, -0.3824, -0.3588, -0.1314,  0.1039,  0.1667,  0.4922,\n",
      "           0.4922,  0.4922,  0.4922,  0.4922,  0.3824,  0.1745,  0.4922,\n",
      "           0.4490,  0.2647, -0.2490, -0.5000, -0.5000, -0.5000, -0.5000],\n",
      "         [-0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
      "          -0.3078,  0.4333,  0.4922,  0.4922,  0.4922,  0.4922,  0.4922,\n",
      "           0.4922,  0.4922,  0.4922,  0.4843, -0.1353, -0.1784, -0.1784,\n",
      "          -0.2804, -0.3471, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000],\n",
      "         [-0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
      "          -0.4294,  0.3588,  0.4922,  0.4922,  0.4922,  0.4922,  0.4922,\n",
      "           0.2765,  0.2137,  0.4686,  0.4451, -0.5000, -0.5000, -0.5000,\n",
      "          -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000],\n",
      "         [-0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
      "          -0.5000, -0.1863,  0.1118, -0.0804,  0.4922,  0.4922,  0.3039,\n",
      "          -0.4569, -0.5000, -0.3314,  0.1039, -0.5000, -0.5000, -0.5000,\n",
      "          -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000],\n",
      "         [-0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
      "          -0.5000, -0.5000, -0.4451, -0.4961,  0.1039,  0.4922, -0.1471,\n",
      "          -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
      "          -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000],\n",
      "         [-0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
      "          -0.5000, -0.5000, -0.5000, -0.5000,  0.0451,  0.4922,  0.2451,\n",
      "          -0.4922, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
      "          -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000],\n",
      "         [-0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
      "          -0.5000, -0.5000, -0.5000, -0.5000, -0.4569,  0.2451,  0.4922,\n",
      "          -0.2255, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
      "          -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000],\n",
      "         [-0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
      "          -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.3627,  0.4451,\n",
      "           0.3824,  0.1275, -0.0765, -0.4961, -0.5000, -0.5000, -0.5000,\n",
      "          -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000],\n",
      "         [-0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
      "          -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.1824,\n",
      "           0.4412,  0.4922,  0.4922, -0.0333, -0.4020, -0.5000, -0.5000,\n",
      "          -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000],\n",
      "         [-0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
      "          -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
      "          -0.3235,  0.2294,  0.4922,  0.4922,  0.0882, -0.3941, -0.5000,\n",
      "          -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000],\n",
      "         [-0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
      "          -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
      "          -0.5000, -0.4373, -0.1353,  0.4882,  0.4922,  0.2333, -0.5000,\n",
      "          -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000],\n",
      "         [-0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
      "          -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
      "          -0.5000, -0.5000, -0.5000,  0.4765,  0.4922,  0.4765, -0.2490,\n",
      "          -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000],\n",
      "         [-0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
      "          -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
      "          -0.3196,  0.0098,  0.2176,  0.4922,  0.4922,  0.3118, -0.4922,\n",
      "          -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000],\n",
      "         [-0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
      "          -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.3471,  0.0804,\n",
      "           0.3980,  0.4922,  0.4922,  0.4922,  0.4804,  0.2137, -0.5000,\n",
      "          -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000],\n",
      "         [-0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
      "          -0.5000, -0.5000, -0.5000, -0.4059, -0.0529,  0.3667,  0.4922,\n",
      "           0.4922,  0.4922,  0.4922,  0.2882, -0.1941, -0.5000, -0.5000,\n",
      "          -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000],\n",
      "         [-0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
      "          -0.5000, -0.4098, -0.2412,  0.3353,  0.4922,  0.4922,  0.4922,\n",
      "           0.4922,  0.2765, -0.1824, -0.4922, -0.5000, -0.5000, -0.5000,\n",
      "          -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000],\n",
      "         [-0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.4294,\n",
      "           0.1706,  0.3588,  0.4922,  0.4922,  0.4922,  0.4922,  0.2647,\n",
      "          -0.1863, -0.4647, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
      "          -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000],\n",
      "         [-0.5000, -0.5000, -0.5000, -0.5000, -0.2843,  0.1745,  0.3863,\n",
      "           0.4922,  0.4922,  0.4922,  0.4922,  0.4569,  0.0216, -0.4569,\n",
      "          -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
      "          -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000],\n",
      "         [-0.5000, -0.5000, -0.5000, -0.5000,  0.0333,  0.4922,  0.4922,\n",
      "           0.4922,  0.3314,  0.0294,  0.0176, -0.4373, -0.5000, -0.5000,\n",
      "          -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
      "          -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000],\n",
      "         [-0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
      "          -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
      "          -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
      "          -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000],\n",
      "         [-0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
      "          -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
      "          -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
      "          -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000],\n",
      "         [-0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
      "          -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
      "          -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000,\n",
      "          -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000, -0.5000]]]), tensor(5))\n"
     ]
    }
   ],
   "source": [
    "print(\"Training target 0:\", train_dset.__getitem__(0))\n",
    "train_item = train_dset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_item[1])\n",
    "\n",
    "train_item[1].item()\n",
    "\n",
    "train_dset.__getitem__(0)[1].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport random\\nsample_biases = [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\\n\\n# takes a global training set, a global test set, and a ten-element list of biases as floats from 0.0 to 1.0\\ndef stacked_decks(train_dset, test_dset, biases):\\n\\n    for i in range(len(train_dset)):\\n        target_value = train_dset.__getitem__(i)[1].item()\\n        if(random.uniform(0.0, 1.0) <= biases[target_value]): train_targets[target_value].append(i)\\n\\n    stacked_train = Subset(train_dset, train_targets)\\n        \\n    for i in range(len(test_dset)):\\n        target_value = test_dset.__getitem__(i)[1].item()\\n        if(random.uniform(0.0, 1.0) <= biases[target_value]): test_targets[target_value].append(i)\\n        \\n    stacked_test = Subset(test_dset, test_targets)\\n\\n    return stacked_train, stacked_test\\n\\n\\nsttrain, sttest = stacked_decks(train_dset, test_dset, sample_biases)\\n\\nprint(\"sstrain length: \", sttrain.__getitem__(0)[1].item())\\nprint(\"sstest length: \", type(sttest))\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets = [[],[],[],[],[],[],[],[],[],[]]\n",
    "test_targets = [[],[],[],[],[],[],[],[],[],[]]\n",
    "\n",
    "for i in range(len(train_dset)):\n",
    "    #print(\"i:\", i, \"target_value:\", target_value)\n",
    "    target_value = train_dset.__getitem__(i)[1].item()\n",
    "    train_targets[target_value].append(i)\n",
    "\n",
    "for i in range(len(test_dset)):\n",
    "    #print(\"i:\", i, \"target_value:\", target_value)\n",
    "    target_value = test_dset.__getitem__(i)[1].item()\n",
    "    test_targets[target_value].append(i)\n",
    "\n",
    "\"\"\"\n",
    "import random\n",
    "sample_biases = [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
    "\n",
    "# takes a global training set, a global test set, and a ten-element list of biases as floats from 0.0 to 1.0\n",
    "def stacked_decks(train_dset, test_dset, biases):\n",
    "\n",
    "    for i in range(len(train_dset)):\n",
    "        target_value = train_dset.__getitem__(i)[1].item()\n",
    "        if(random.uniform(0.0, 1.0) <= biases[target_value]): train_targets[target_value].append(i)\n",
    "\n",
    "    stacked_train = Subset(train_dset, train_targets)\n",
    "        \n",
    "    for i in range(len(test_dset)):\n",
    "        target_value = test_dset.__getitem__(i)[1].item()\n",
    "        if(random.uniform(0.0, 1.0) <= biases[target_value]): test_targets[target_value].append(i)\n",
    "        \n",
    "    stacked_test = Subset(test_dset, test_targets)\n",
    "\n",
    "    return stacked_train, stacked_test\n",
    "\n",
    "\n",
    "sttrain, sttest = stacked_decks(train_dset, test_dset, sample_biases)\n",
    "\n",
    "print(\"sstrain length: \", sttrain.__getitem__(0)[1].item())\n",
    "print(\"sstest length: \", type(sttest))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import Subset\n",
    "\n",
    "train_subset_zeros = Subset(train_dset, train_targets[0])\n",
    "train_subset_ones = Subset(train_dset, train_targets[1])\n",
    "train_subset_twos = Subset(train_dset, train_targets[2])\n",
    "train_subset_threes = Subset(train_dset, train_targets[3])\n",
    "train_subset_fours = Subset(train_dset, train_targets[4])\n",
    "train_subset_fives = Subset(train_dset, train_targets[5])\n",
    "train_subset_sixes = Subset(train_dset, train_targets[6])\n",
    "train_subset_sevens = Subset(train_dset, train_targets[7])\n",
    "train_subset_eights = Subset(train_dset, train_targets[8])\n",
    "train_subset_nines = Subset(train_dset, train_targets[9])\n",
    "\n",
    "test_subset_zeros = Subset(test_dset, test_targets[0])\n",
    "test_subset_ones = Subset(test_dset, test_targets[1])\n",
    "test_subset_twos = Subset(test_dset, test_targets[2])\n",
    "test_subset_threes = Subset(test_dset, test_targets[3])\n",
    "test_subset_fours = Subset(test_dset, test_targets[4])\n",
    "test_subset_fives = Subset(test_dset, test_targets[5])\n",
    "test_subset_sixes = Subset(test_dset, test_targets[6])\n",
    "test_subset_sevens = Subset(test_dset, test_targets[7])\n",
    "test_subset_eights = Subset(test_dset, test_targets[8])\n",
    "test_subset_nines = Subset(test_dset, test_targets[9])\n",
    "\n",
    "\n",
    "#for i in range(len(test_subset_zeros)): print(test_subset_zeros.__getitem__(i)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dloader: 1875 test_dloader: 313\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# create dataloaders\n",
    "batch_size = 32\n",
    "\n",
    "train_dloader = DataLoader(train_dset, batch_size=batch_size, shuffle=True)\n",
    "test_dloader = DataLoader(test_dset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "#train_dloader = DataLoader(train_subset_sevens, batch_size=batch_size, shuffle=True)\n",
    "#test_dloader = DataLoader(test_subset_sevens, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(\"train_dloader:\", len(train_dloader), \"test_dloader:\", len(test_dloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MLPNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLPNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 500)\n",
    "        self.fc2 = nn.Linear(500, 256)\n",
    "        self.fc3 = nn.Linear(256, 10)\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = nn.functional.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def name(self):\n",
    "        return \"MLP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   0, batch index:  187, train loss: 1.85183\n",
      "epoch:   0, batch index:  374, train loss: 0.88481\n",
      "epoch:   0, batch index:  561, train loss: 0.56637\n",
      "epoch:   0, batch index:  748, train loss: 0.45749\n",
      "epoch:   0, batch index:  935, train loss: 0.48962\n",
      "epoch:   0, batch index: 1122, train loss: 0.37287\n",
      "epoch:   0, batch index: 1309, train loss: 0.39963\n",
      "epoch:   0, batch index: 1496, train loss: 0.35238\n",
      "epoch:   0, batch index: 1683, train loss: 0.36752\n",
      "epoch:   0, batch index: 1870, train loss: 0.31201\n",
      "epoch:   0, batch index: 1875, train loss: 0.33383\n",
      "==>>> epoch: 0, batch index: 313, test loss: 0.38054, acc: 0.905\n",
      "epoch:   1, batch index:  187, train loss: 0.35131\n",
      "epoch:   1, batch index:  374, train loss: 0.32125\n",
      "epoch:   1, batch index:  561, train loss: 0.29272\n",
      "epoch:   1, batch index:  748, train loss: 0.28958\n",
      "epoch:   1, batch index:  935, train loss: 0.28810\n",
      "epoch:   1, batch index: 1122, train loss: 0.27933\n",
      "epoch:   1, batch index: 1309, train loss: 0.28641\n",
      "epoch:   1, batch index: 1496, train loss: 0.21696\n",
      "epoch:   1, batch index: 1683, train loss: 0.21982\n",
      "epoch:   1, batch index: 1870, train loss: 0.29270\n",
      "epoch:   1, batch index: 1875, train loss: 0.27470\n",
      "==>>> epoch: 1, batch index: 313, test loss: 0.33233, acc: 0.921\n",
      "epoch:   2, batch index:  187, train loss: 0.30355\n",
      "epoch:   2, batch index:  374, train loss: 0.21495\n",
      "epoch:   2, batch index:  561, train loss: 0.29812\n",
      "epoch:   2, batch index:  748, train loss: 0.21318\n",
      "epoch:   2, batch index:  935, train loss: 0.26614\n",
      "epoch:   2, batch index: 1122, train loss: 0.20913\n",
      "epoch:   2, batch index: 1309, train loss: 0.31046\n",
      "epoch:   2, batch index: 1496, train loss: 0.22168\n",
      "epoch:   2, batch index: 1683, train loss: 0.20244\n",
      "epoch:   2, batch index: 1870, train loss: 0.18868\n",
      "epoch:   2, batch index: 1875, train loss: 0.22098\n",
      "==>>> epoch: 2, batch index: 313, test loss: 0.24522, acc: 0.940\n",
      "epoch:   3, batch index:  187, train loss: 0.20353\n",
      "epoch:   3, batch index:  374, train loss: 0.21013\n",
      "epoch:   3, batch index:  561, train loss: 0.15999\n",
      "epoch:   3, batch index:  748, train loss: 0.18036\n",
      "epoch:   3, batch index:  935, train loss: 0.21371\n",
      "epoch:   3, batch index: 1122, train loss: 0.15564\n",
      "epoch:   3, batch index: 1309, train loss: 0.18075\n",
      "epoch:   3, batch index: 1496, train loss: 0.15541\n",
      "epoch:   3, batch index: 1683, train loss: 0.17236\n",
      "epoch:   3, batch index: 1870, train loss: 0.17420\n",
      "epoch:   3, batch index: 1875, train loss: 0.17899\n",
      "==>>> epoch: 3, batch index: 313, test loss: 0.22882, acc: 0.948\n",
      "epoch:   4, batch index:  187, train loss: 0.15030\n",
      "epoch:   4, batch index:  374, train loss: 0.14440\n",
      "epoch:   4, batch index:  561, train loss: 0.12912\n",
      "epoch:   4, batch index:  748, train loss: 0.17813\n",
      "epoch:   4, batch index:  935, train loss: 0.15518\n",
      "epoch:   4, batch index: 1122, train loss: 0.15635\n",
      "epoch:   4, batch index: 1309, train loss: 0.14969\n",
      "epoch:   4, batch index: 1496, train loss: 0.15291\n",
      "epoch:   4, batch index: 1683, train loss: 0.13005\n",
      "epoch:   4, batch index: 1870, train loss: 0.14973\n",
      "epoch:   4, batch index: 1875, train loss: 0.14656\n",
      "==>>> epoch: 4, batch index: 313, test loss: 0.19689, acc: 0.957\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = MLPNet()\n",
    "\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "num_epochs = 5\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_loss_history = []\n",
    "test_loss_history = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    # train\n",
    "    avg_loss = 0\n",
    "    for batch_idx, (x, target) in enumerate(train_dloader):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x)\n",
    "        loss = criterion(out, target)\n",
    "        if(batch_idx % int(len(train_dloader)/len(test_dloader)) == 0): train_loss_history.append(loss.item())\n",
    "        #train_loss_history.append(loss.item())\n",
    "        avg_loss = avg_loss * 0.9 + loss.item() * 0.1\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "                    \n",
    "        if (batch_idx+1) % int(len(train_dloader)/10) == 0 or (batch_idx+1) == len(train_dloader):\n",
    "            print ('epoch: {:3d}, batch index: {:4d}, train loss: {:.5f}'.format(\n",
    "                epoch, batch_idx+1, avg_loss))     \n",
    "            \n",
    "    # test\n",
    "    correct_cnt, total_cnt, ave_loss = 0, 0, 0\n",
    "    avg_loss = 0\n",
    "    \n",
    "    for batch_idx, (x, target) in enumerate(test_dloader):\n",
    "        out = model(x)\n",
    "        loss = criterion(out, target)\n",
    "        test_loss_history.append(loss.item())\n",
    "        _, pred_label = torch.max(out.data, 1)\n",
    "        total_cnt += x.data.size()[0]\n",
    "        correct_cnt += (pred_label == target.data).sum()\n",
    "        \n",
    "        #print(pred_label, target.data)\n",
    "        #print(x.data.size()[0], (pred_label == target.data).sum().item())\n",
    "        #print(correct_cnt, total_cnt)\n",
    "        \n",
    "        \n",
    "        # smooth average\n",
    "        avg_loss = avg_loss * 0.9 + loss.item() * 0.1\n",
    "        \n",
    "        if(batch_idx+1) % 500 == 0 or (batch_idx+1) == len(test_dloader):\n",
    "            print ('==>>> epoch: {}, batch index: {}, test loss: {:.5f}, acc: {:.3f}'.format(\n",
    "                epoch, batch_idx+1, avg_loss, correct_cnt.item() * 1.0 / total_cnt))\n",
    "\n",
    "#TODO GET TEST LOSS AND ACCURACY CORRECT\n",
    "#TODO SCALE TEST LOSS TO MATCH TRAIN LOSS FOR PLOTTING\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(train_loss_history, label=\"train\");\n",
    "ax.plot(test_loss_history, label=\"test\");\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
